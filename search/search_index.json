{
    "docs": [
        {
            "location": "/",
            "text": "About\n\n\nATLAS Analytics consists of numerous databases and services running at several distributed computing clusters, managed by different groups.\n\n\nThis documentation will try to provide one stop documentation to all our users.\nA brief overview of the system can be found  ...\n\n\nPlease feel free to update directly in the GitHub repository. To get access or rebuild the site please contact Ilija Vukotic.\n\n\nQuick links\n\n\n\n\n\n\n\n\nMonitoring\n\n\nAnalytics\n\n\n\n\n\n\n\n\n\n\nbigPanda\n\n\nJupyter UC\n\n\n\n\n\n\nES UChicago\n\n\n\n\n\n\n\n\nES CERN\n\n\n\n\n\n\n\n\nMonit",
            "title": "Home"
        },
        {
            "location": "/#about",
            "text": "ATLAS Analytics consists of numerous databases and services running at several distributed computing clusters, managed by different groups.  This documentation will try to provide one stop documentation to all our users.\nA brief overview of the system can be found  ...  Please feel free to update directly in the GitHub repository. To get access or rebuild the site please contact Ilija Vukotic.",
            "title": "About"
        },
        {
            "location": "/#quick-links",
            "text": "Monitoring  Analytics      bigPanda  Jupyter UC    ES UChicago     ES CERN     Monit",
            "title": "Quick links"
        },
        {
            "location": "/sites/",
            "text": "Site administration\n\n\nStorage\n\n\nJobs IO\n\n\nSite movers collect information on all the input/output data transfers from the job. This data gets collected and indexed in ES at both CERN and UChicago. The data contains information on all the files that job accessesed or wrote, file sizes, rates, and a lot of metadata (filenames,workernode, etc.). Sites can use this data to:\n\n\n\n\n\n\nspot problematics WN (full or failed scratch disk, connection issue, missconfiguration)\n\n\n\n\n\n\nspot LAN issues (bad links, congested switches, ...)\n\n\n\n\n\n\noptimize access type (copy-to-scratch)\n\n\n\n\n\n\nJobs\n\n\nNetwork issues",
            "title": "Sites"
        },
        {
            "location": "/sites/#site-administration",
            "text": "",
            "title": "Site administration"
        },
        {
            "location": "/sites/#storage",
            "text": "",
            "title": "Storage"
        },
        {
            "location": "/sites/#jobs-io",
            "text": "Site movers collect information on all the input/output data transfers from the job. This data gets collected and indexed in ES at both CERN and UChicago. The data contains information on all the files that job accessesed or wrote, file sizes, rates, and a lot of metadata (filenames,workernode, etc.). Sites can use this data to:    spot problematics WN (full or failed scratch disk, connection issue, missconfiguration)    spot LAN issues (bad links, congested switches, ...)    optimize access type (copy-to-scratch)",
            "title": "Jobs IO"
        },
        {
            "location": "/sites/#jobs",
            "text": "",
            "title": "Jobs"
        },
        {
            "location": "/sites/#network-issues",
            "text": "",
            "title": "Network issues"
        },
        {
            "location": "/ADC/",
            "text": "ADC\n\n\nFTS performance\n\n\nJob efficiency",
            "title": "ADC"
        },
        {
            "location": "/ADC/#adc",
            "text": "",
            "title": "ADC"
        },
        {
            "location": "/ADC/#fts-performance",
            "text": "",
            "title": "FTS performance"
        },
        {
            "location": "/ADC/#job-efficiency",
            "text": "",
            "title": "Job efficiency"
        },
        {
            "location": "/accounting/",
            "text": "Accounting\n\n\nClouds",
            "title": "Accounting"
        },
        {
            "location": "/accounting/#accounting",
            "text": "",
            "title": "Accounting"
        },
        {
            "location": "/accounting/#clouds",
            "text": "",
            "title": "Clouds"
        },
        {
            "location": "/data-sources/Distributed_processing/",
            "text": "Distributed processing\n\n\nJobs\n\n\nEnrichments\n\n\nParent-child relationship\n\n\nWhen a job needs to be restarted for whatever reason, it gets a new pandaID. It can actually be restarted at more than one place. Information on parent/child relationship between jobs is stored in OracleDN table \nthis\n. A sqoop job gets this info to HDFS from where a pyton codes reads it and uses it to update values in ES at UC.\n\n\nJob status\n\n\nEvery time job changes a state (defined \nhere\n ) one row is added to panda_job_status table with the new state and timestamp.\nThis information is collected by a sqoop script, and saved in hdfs. Another pig script will read it from there, calculate time job spent in any of the states and add these times to jobs archive UC Elasticsearch indices. Variables are:\n\n\nTasks\n\n\nEnrichments",
            "title": "Distributed Processing"
        },
        {
            "location": "/data-sources/Distributed_processing/#distributed-processing",
            "text": "",
            "title": "Distributed processing"
        },
        {
            "location": "/data-sources/Distributed_processing/#jobs",
            "text": "",
            "title": "Jobs"
        },
        {
            "location": "/data-sources/Distributed_processing/#enrichments",
            "text": "",
            "title": "Enrichments"
        },
        {
            "location": "/data-sources/Distributed_processing/#parent-child-relationship",
            "text": "When a job needs to be restarted for whatever reason, it gets a new pandaID. It can actually be restarted at more than one place. Information on parent/child relationship between jobs is stored in OracleDN table  this . A sqoop job gets this info to HDFS from where a pyton codes reads it and uses it to update values in ES at UC.",
            "title": "Parent-child relationship"
        },
        {
            "location": "/data-sources/Distributed_processing/#job-status",
            "text": "Every time job changes a state (defined  here  ) one row is added to panda_job_status table with the new state and timestamp.\nThis information is collected by a sqoop script, and saved in hdfs. Another pig script will read it from there, calculate time job spent in any of the states and add these times to jobs archive UC Elasticsearch indices. Variables are:",
            "title": "Job status"
        },
        {
            "location": "/data-sources/Distributed_processing/#tasks",
            "text": "",
            "title": "Tasks"
        },
        {
            "location": "/data-sources/Distributed_processing/#enrichments_1",
            "text": "",
            "title": "Enrichments"
        },
        {
            "location": "/data-sources/fts/",
            "text": "FTS\n\n\nDOCS\n\n\n\n\nMain google doc\n\n\nFTS3 configuration\n\n\nFTS3 Optimizer\n\n\n\n\nFTS servers\n\n\nConfigurations per FTS Server\n\n\n\n\nCERN\n\n\nBNL\n\n\n\n\nMonitoring @CERN\n\n\nMonit:\n\n\n\n\nGrafana\n\n\nKibana\n\n\n\n\nMonitoring @UC\n\n\nGlobally most important \nFTS queue waits.\n\n\nComparissons of average queue times for transfers where destination is \nUS or not US.\n\n\nSite specific dashboards:\n\n\n\n\nMWT2 \nQueues\n \nTransfers\n\n\nAGLT2 \nQueues\n \nTransfers\n\n\nBNL \nTransfers\n\n\n\n\nMonitoring flow description",
            "title": "FTS"
        },
        {
            "location": "/data-sources/fts/#fts",
            "text": "",
            "title": "FTS"
        },
        {
            "location": "/data-sources/fts/#docs",
            "text": "Main google doc  FTS3 configuration  FTS3 Optimizer",
            "title": "DOCS"
        },
        {
            "location": "/data-sources/fts/#fts-servers",
            "text": "Configurations per FTS Server   CERN  BNL",
            "title": "FTS servers"
        },
        {
            "location": "/data-sources/fts/#monitoring-cern",
            "text": "Monit:   Grafana  Kibana",
            "title": "Monitoring @CERN"
        },
        {
            "location": "/data-sources/fts/#monitoring-uc",
            "text": "Globally most important  FTS queue waits.  Comparissons of average queue times for transfers where destination is  US or not US.  Site specific dashboards:   MWT2  Queues   Transfers  AGLT2  Queues   Transfers  BNL  Transfers",
            "title": "Monitoring @UC"
        },
        {
            "location": "/data-sources/fts/#monitoring-flow-description",
            "text": "",
            "title": "Monitoring flow description"
        },
        {
            "location": "/data-sources/perfsonar/",
            "text": "PerfSONAR\n\n\nData collection\n\n\nPerfsonar data gets sent to Nebraska RabbitMQ. From there it gets sent to Fermilab for storage on tape, to ES at UChicago and to ES at Nebraska. \n\n\nCollectors are in a docker container auto-built in dockerHub:              \nivukotic/perfsonar_collectors\n\n\nData analysis\n\n\nThere is a whole docker container with a number of tools and services:         \nopensciencegrid/network_analytics\n \n\n\nIt has apache web server, neo4j server, jupyter lab server. All of it is easily deployable on a k8s cluster.",
            "title": "PerfSONAR"
        },
        {
            "location": "/data-sources/perfsonar/#perfsonar",
            "text": "",
            "title": "PerfSONAR"
        },
        {
            "location": "/data-sources/perfsonar/#data-collection",
            "text": "Perfsonar data gets sent to Nebraska RabbitMQ. From there it gets sent to Fermilab for storage on tape, to ES at UChicago and to ES at Nebraska.   Collectors are in a docker container auto-built in dockerHub:               ivukotic/perfsonar_collectors",
            "title": "Data collection"
        },
        {
            "location": "/data-sources/perfsonar/#data-analysis",
            "text": "There is a whole docker container with a number of tools and services:          opensciencegrid/network_analytics    It has apache web server, neo4j server, jupyter lab server. All of it is easily deployable on a k8s cluster.",
            "title": "Data analysis"
        },
        {
            "location": "/data-sources/xaod/",
            "text": "xAOD monitoring\n\n\nCode that is needed in order to access xAOD data has been instrumented (WHERE???) so it collects information on containers and branches accessed by the user.\n\n\nThis data is reported to a RUCIO appache server that stores it in HDFS. (Who takes care of this??? Where is it documented???)\n\n\nOnce a day information from HDFS is processed using a pig script and a python code and sent to Elasticsearch cluster at UChicago. This code can be found in \nGitHub\n.\n\n\nHDFS @CERN\n\n\nData is in: \nhdfs://analytix//user/rucio01/nongrid_traces/$INPD.json\n\n\nElasticsearch at UChicago\n\n\nData is stored in two indices:\n\n\n\n\n\n\ninformation per job.  Index is named: \nxaod_accesses\n  Template is \nhere\n. Data is produced and indexed directly by the pig script. \n\n\n\n\n\n\ncontainer or branch access. Index is named: \nxaod_job_accesses\n  Template is \nhere\n.\n\n\n\n\n\n\nDashboards\n\n\nAnalysis\n\n\nHere links to relevant Jupyter notebooks.1",
            "title": "xAOD"
        },
        {
            "location": "/data-sources/xaod/#xaod-monitoring",
            "text": "Code that is needed in order to access xAOD data has been instrumented (WHERE???) so it collects information on containers and branches accessed by the user.  This data is reported to a RUCIO appache server that stores it in HDFS. (Who takes care of this??? Where is it documented???)  Once a day information from HDFS is processed using a pig script and a python code and sent to Elasticsearch cluster at UChicago. This code can be found in  GitHub .",
            "title": "xAOD monitoring"
        },
        {
            "location": "/data-sources/xaod/#hdfs-cern",
            "text": "Data is in:  hdfs://analytix//user/rucio01/nongrid_traces/$INPD.json",
            "title": "HDFS @CERN"
        },
        {
            "location": "/data-sources/xaod/#elasticsearch-at-uchicago",
            "text": "Data is stored in two indices:    information per job.  Index is named:  xaod_accesses   Template is  here . Data is produced and indexed directly by the pig script.     container or branch access. Index is named:  xaod_job_accesses   Template is  here .",
            "title": "Elasticsearch at UChicago"
        },
        {
            "location": "/data-sources/xaod/#dashboards",
            "text": "",
            "title": "Dashboards"
        },
        {
            "location": "/data-sources/xaod/#analysis",
            "text": "Here links to relevant Jupyter notebooks.1",
            "title": "Analysis"
        },
        {
            "location": "/data-sources/benchmarks/",
            "text": "",
            "title": "Benchmarks"
        },
        {
            "location": "/data-sources/rtt/",
            "text": "",
            "title": "RTT"
        },
        {
            "location": "/data-sources/esnet/",
            "text": "ESnet\n\n\nData collection\n\n\nThanks to Jon Dugan we can collect data from ESnet \nREST interface\n and send it to ES at UChicago. \nCollector is in \nGitHub repo\n while a docker container is auto-built in dockerHub: \natlasanalyticsservice/esnet\n.\n\n\nData analysis\n\n\nWe still did not start analyzing this data. Once we do, it will be done using tools and services of docker container:        \nopensciencegrid/network_analytics",
            "title": "ESnet"
        },
        {
            "location": "/data-sources/esnet/#esnet",
            "text": "",
            "title": "ESnet"
        },
        {
            "location": "/data-sources/esnet/#data-collection",
            "text": "Thanks to Jon Dugan we can collect data from ESnet  REST interface  and send it to ES at UChicago. \nCollector is in  GitHub repo  while a docker container is auto-built in dockerHub:  atlasanalyticsservice/esnet .",
            "title": "Data collection"
        },
        {
            "location": "/data-sources/esnet/#data-analysis",
            "text": "We still did not start analyzing this data. Once we do, it will be done using tools and services of docker container:         opensciencegrid/network_analytics",
            "title": "Data analysis"
        },
        {
            "location": "/infrastructure/computing_nodes/",
            "text": "Old infrastructure\n\n\nNodes\n\n\naianalytics nodes\n\n\nOpenStack environment variables set for Project = 'ATLAS Services Analytics'\n\n\n\n\n\n\n\n\nNode\n\n\nLocation\n\n\n\n\n\n\n\n\n\n\naianalytics01\n\n\ncern-geneva-b\n\n\n\n\n\n\naianalytics03\n\n\ncern-geneva-b\n\n\n\n\n\n\naianalytics10\n\n\ncern-geneva-a\n\n\n\n\n\n\naianalytics12\n\n\ncern-wigner-a\n\n\n\n\n\n\naianalytics13\n\n\ncern-wigner-a\n\n\n\n\n\n\naianalytics14\n\n\ncern-geneva-c\n\n\n\n\n\n\naianalytics15\n\n\ncern-geneva-c\n\n\n\n\n\n\naianalytics16\n\n\ncern-geneva-a\n\n\n\n\n\n\n\n\naiatlas013 | cern-wigner-b \naiatlas025 | cern-wigner-b \n\n\n\n\naiatlas114.cern.ch\n\n\n\n\nAccounts\n\n\nadcmusr3 is a fax monitoring account running things on aiatlas114.cern.ch\n  aflume - service account \n\n\nNew infrastructure\n\n\nNodes\n\n\nAccounts\n\n\n\n\n\n\n\n\nName\n\n\nLogin\n\n\nEmail\n\n\n\n\n\n\n\n\n\n\nATLAS analytics service\n\n\nanalyticssvc\n\n\nanalytics.service@cern.ch\n\n\n\n\n\n\nATLAS analytics\n\n\nanalytics\n\n\natlas.analytics@cern.ch",
            "title": "Backend nodes "
        },
        {
            "location": "/infrastructure/computing_nodes/#old-infrastructure",
            "text": "",
            "title": "Old infrastructure"
        },
        {
            "location": "/infrastructure/computing_nodes/#nodes",
            "text": "",
            "title": "Nodes"
        },
        {
            "location": "/infrastructure/computing_nodes/#aianalytics-nodes",
            "text": "OpenStack environment variables set for Project = 'ATLAS Services Analytics'     Node  Location      aianalytics01  cern-geneva-b    aianalytics03  cern-geneva-b    aianalytics10  cern-geneva-a    aianalytics12  cern-wigner-a    aianalytics13  cern-wigner-a    aianalytics14  cern-geneva-c    aianalytics15  cern-geneva-c    aianalytics16  cern-geneva-a     aiatlas013 | cern-wigner-b \naiatlas025 | cern-wigner-b    aiatlas114.cern.ch",
            "title": "aianalytics nodes"
        },
        {
            "location": "/infrastructure/computing_nodes/#accounts",
            "text": "adcmusr3 is a fax monitoring account running things on aiatlas114.cern.ch\n  aflume - service account",
            "title": "Accounts"
        },
        {
            "location": "/infrastructure/computing_nodes/#new-infrastructure",
            "text": "",
            "title": "New infrastructure"
        },
        {
            "location": "/infrastructure/computing_nodes/#nodes_1",
            "text": "",
            "title": "Nodes"
        },
        {
            "location": "/infrastructure/computing_nodes/#accounts_1",
            "text": "Name  Login  Email      ATLAS analytics service  analyticssvc  analytics.service@cern.ch    ATLAS analytics  analytics  atlas.analytics@cern.ch",
            "title": "Accounts"
        },
        {
            "location": "/infrastructure/analytics/",
            "text": "",
            "title": "Analytics"
        },
        {
            "location": "/infrastructure/amq/",
            "text": "",
            "title": "AMQ"
        },
        {
            "location": "/infrastructure/elasticsearch/",
            "text": "Elasticsearch\n\n\nUChicago\n\n\nInfrastructure\n\n\n\n\n5 data nodes, 3 service nodes (3 masters, 2 kibana), 15 TB of SSDs. Will be expanded to:...\n\n\nbackup: each Sunday all data is incrementally backed up.\n\n\n\n\nKibana\n\n\n\n\nProduction\n\n\n\n\nProduction version\n is fully open but only for read access. Searches, visualization, dashboards can be created but can not be saved. To add something to it one has to create it first in the development and ask Ilija to copy it over to the production Kibana.\n\n\n\n\nDevelopment\n\nDevelopment version\n is read/write capable but sits behind a apache proxy, if you need a password ask Ilija Vukotic.\n\n\n\n\nIT-ES\n\n\nMonit",
            "title": "Elasticsearch"
        },
        {
            "location": "/infrastructure/elasticsearch/#elasticsearch",
            "text": "",
            "title": "Elasticsearch"
        },
        {
            "location": "/infrastructure/elasticsearch/#uchicago",
            "text": "",
            "title": "UChicago"
        },
        {
            "location": "/infrastructure/elasticsearch/#infrastructure",
            "text": "5 data nodes, 3 service nodes (3 masters, 2 kibana), 15 TB of SSDs. Will be expanded to:...  backup: each Sunday all data is incrementally backed up.",
            "title": "Infrastructure"
        },
        {
            "location": "/infrastructure/elasticsearch/#kibana",
            "text": "Production   Production version  is fully open but only for read access. Searches, visualization, dashboards can be created but can not be saved. To add something to it one has to create it first in the development and ask Ilija to copy it over to the production Kibana.   Development Development version  is read/write capable but sits behind a apache proxy, if you need a password ask Ilija Vukotic.",
            "title": "Kibana"
        },
        {
            "location": "/infrastructure/elasticsearch/#it-es",
            "text": "",
            "title": "IT-ES"
        },
        {
            "location": "/infrastructure/elasticsearch/#monit",
            "text": "",
            "title": "Monit"
        },
        {
            "location": "/infrastructure/hadoop/",
            "text": "",
            "title": "Hadoop"
        },
        {
            "location": "/infrastructure/logstash/",
            "text": "",
            "title": "Logstash"
        },
        {
            "location": "/alarms_and_alerts/",
            "text": "Alarms & Alerts\n\n\nWe are periodically running a number of different checks. When these checks fail we generate an \nAlarm\n. When a person gets an e-mail concerning an alarm, we call that an \nAlert\n. \nAt the moment tests are running as cron jobs on our main analytics node (uct3-lx2.uchicago.edu).",
            "title": "Alarms and Alerts"
        },
        {
            "location": "/alarms_and_alerts/#alarms-alerts",
            "text": "We are periodically running a number of different checks. When these checks fail we generate an  Alarm . When a person gets an e-mail concerning an alarm, we call that an  Alert . \nAt the moment tests are running as cron jobs on our main analytics node (uct3-lx2.uchicago.edu).",
            "title": "Alarms &amp; Alerts"
        },
        {
            "location": "/user-guide/es_and_kibana/",
            "text": "ES and Kibana",
            "title": "Elasticsearch & Kibana"
        },
        {
            "location": "/user-guide/es_and_kibana/#es-and-kibana",
            "text": "",
            "title": "ES and Kibana"
        },
        {
            "location": "/user-guide/hadoop/",
            "text": "",
            "title": "Hadoop"
        },
        {
            "location": "/user-guide/spark/",
            "text": "",
            "title": "Spark"
        },
        {
            "location": "/user-guide/pig/",
            "text": "",
            "title": "Pig Latin"
        },
        {
            "location": "/user-guide/jupyter/",
            "text": "",
            "title": "Jupyter"
        }
    ]
}